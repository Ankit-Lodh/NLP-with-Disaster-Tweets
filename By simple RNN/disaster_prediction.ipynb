{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bIwPHlM356r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6102cbd2-ad87-4e78-f5df-0a90da5404b0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EwnZRobEjVJ",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "76c85b4c-db70-471c-cce7-0c2f3f42c136"
      },
      "source": [
        "from google.colab import files\n",
        "upload = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-54459a02-0082-4d0f-8088-32badeaa5bec\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-54459a02-0082-4d0f-8088-32badeaa5bec\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train.csv to train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtjONyJrE9io"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk \n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKLwcjzNG8N9"
      },
      "source": [
        "df = pd.read_csv('train.csv')"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMgPmDsCybNj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "532ec62b-2bd0-43a5-fa6f-b92caa52a561"
      },
      "source": [
        "df"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7608</th>\n",
              "      <td>10869</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7609</th>\n",
              "      <td>10870</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7610</th>\n",
              "      <td>10871</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7611</th>\n",
              "      <td>10872</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Police investigating after an e-bike collided ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7612</th>\n",
              "      <td>10873</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id keyword  ...                                               text target\n",
              "0         1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1         4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2         5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3         6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4         7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "...     ...     ...  ...                                                ...    ...\n",
              "7608  10869     NaN  ...  Two giant cranes holding a bridge collapse int...      1\n",
              "7609  10870     NaN  ...  @aria_ahrary @TheTawniest The out of control w...      1\n",
              "7610  10871     NaN  ...  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...      1\n",
              "7611  10872     NaN  ...  Police investigating after an e-bike collided ...      1\n",
              "7612  10873     NaN  ...  The Latest: More Homes Razed by Northern Calif...      1\n",
              "\n",
              "[7613 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYyI1rfZ1Bmb"
      },
      "source": [
        "x_df = df['text']"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulb1F9EgW3fH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c0b85b2-5254-4d6a-bfd3-555860b0db8f"
      },
      "source": [
        "len(x_df)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7613"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32grPGadToRV"
      },
      "source": [
        "x = x_df.values"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exss9vH0biuv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a00638-d8a4-4018-9079-fc58d8849e60"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NEnnSk72G21"
      },
      "source": [
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "# at the case of tokenization we tokenize the word and washout english stop word at the same time\n",
        "def tokenize_word(sentence):\n",
        "    pure_sentence = re.sub(r'[-,?!@:#;+0-9/$\\*]','',sentence)#replace these symbol by space\n",
        "    pure_sentence1 = re.sub(r'[\\'.]','',pure_sentence)\n",
        "    pure_sentence2 = re.sub(r'[][]','',pure_sentence1)\n",
        "    pure_sentence3 = re.sub(r'\\x89..','',pure_sentence2)\n",
        "    pure_sentence4 = re.sub(r'[<=>|]','',pure_sentence3)\n",
        "    pure_sentence5 = re.sub(r'[()]','',pure_sentence4)\n",
        "    token_word = word_tokenize(pure_sentence5)\n",
        "    word = list(filter(lambda x:not x.startswith('https' and 'http'),token_word))\n",
        "    english_stopword = set(stopwords.words('english')) # set of english stopword\n",
        "    filter_word = [w for w in word if w not in english_stopword] # washout english stop word such as 'and','or','the',etc\n",
        "    return filter_word"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KQ1I8xdnLfw"
      },
      "source": [
        "# Now I write a function of replacing words matching regular expression\n",
        "import re\n",
        "replacement_patterns = [\n",
        " (r'won\\'t', 'will not'),\n",
        " (r'can\\'t', 'cannot'),\n",
        " (r'i\\'m', 'i am'),\n",
        " (r'ain\\'t', 'is not'),\n",
        " (r'(\\w+)\\'ll', '\\g<1> will'),\n",
        " (r'(\\w+)n\\'t', '\\g<1> not'),\n",
        " (r'(\\w+)\\'ve', '\\g<1> have'),\n",
        " (r'(\\w+)\\'s', '\\g<1> is'),\n",
        " (r'(\\w+)\\'re', '\\g<1> are'),\n",
        " (r'(\\w+)\\'d', '\\g<1> would')\n",
        "]\n",
        "class Regularexpreplacer:\n",
        "  def __init__(self):\n",
        "    self.pattern = [(re.compile(match),repl) for (match,repl) in replacement_patterns]\n",
        "  def replace(self,text):\n",
        "    k = text\n",
        "    for (p,repl) in self.pattern:\n",
        "      k = re.sub(p,repl,k)\n",
        "    return k"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmqhXBCEqH3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00df70eb-6b9e-4948-a9de-abc820f4a18b"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJlPYfDoINt4"
      },
      "source": [
        "import re\n",
        "class RepeatReplacer:\n",
        "    def __init__(self):\n",
        "        self.repeat_regexp = r'(\\w*)(\\w)\\2(\\w*)'\n",
        "        self.repl = r'\\1\\2\\3'\n",
        "    def replace(self, word):\n",
        "        repl_word = re.sub(self.repeat_regexp ,self.repl, word)\n",
        "        if repl_word != word:\n",
        "            return self.replace(repl_word)\n",
        "        else:\n",
        "            return repl_word"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpJd4o-8QLN6"
      },
      "source": [
        "def get_word(words,c):\n",
        "  i = c\n",
        "  while i < (len(words)-c):\n",
        "    center_word = words[i]\n",
        "    context_word = words[(i-c):i]+words[(i+1):(i+c+1)]\n",
        "    yield center_word,context_word\n",
        "    i+=1"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14YcbX6FnWdF"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "target = []\n",
        "context = []\n",
        "BOW = []\n",
        "for j in range(7610):\n",
        "  tokenize = tokenize_word(Regularexpreplacer().replace(x[j].lower()))\n",
        "  T = [lemmatizer.lemmatize(token) for token in tokenize]\n",
        "#  output = [TextBlob(t).correct() for t in T]\n",
        "  BOW.extend(T)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z57NUxPYV5So",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e30574b-ae06-4d53-edd5-0800b0db06e6"
      },
      "source": [
        "len(BOW)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69024"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4prPb99IPPv"
      },
      "source": [
        "# feel free to use this import \n",
        "from collections import Counter\n",
        "\n",
        "## Build a dictionary that maps words to integers\n",
        "counts = Counter(BOW)\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "vocab_to_int = {word: ii for ii, word in enumerate(vocab,1)} \n",
        "\n",
        "## use the dict to tokenize each review in reviews_split\n",
        "## store the tokenized reviews in reviews_ints\n",
        "reviews_ints = []\n",
        "for j in range(7613):\n",
        "  tokenize = tokenize_word(Regularexpreplacer().replace(x[j].lower()))\n",
        "  T = [lemmatizer.lemmatize(token) for token in tokenize]\n",
        "  reviews_ints.append([vocab_to_int[word] for word in T])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1eArLACH-mW"
      },
      "source": [
        "def pad_features(reviews_ints, seq_length):\n",
        "    ''' Return features of review_ints, where each review is padded with 0's \n",
        "        or truncated to the input seq_length.\n",
        "    '''\n",
        "    ## getting the correct rows x cols shape\n",
        "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
        "    \n",
        "    ## for each review, I grab that review\n",
        "    for i, row in enumerate(reviews_ints):\n",
        "      features[i,:len(row)] = np.array(row)[:seq_length]\n",
        "    \n",
        "    return features"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BksS2GptJF_w"
      },
      "source": [
        "# Test your implementation!\n",
        "\n",
        "seq_length = 30\n",
        "\n",
        "features = pad_features(reviews_ints, seq_length=seq_length)\n",
        "\n",
        "## test statements - do not change - ##\n",
        "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
        "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\""
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5Q-SVu-E565",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3520f6a-3acb-446d-b04c-e16872930e63"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJWp1q7aJUL7"
      },
      "source": [
        "y = df['target'].values"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UTOS8c-JNsl"
      },
      "source": [
        "split_frac = 0.8\n",
        "\n",
        "## split data into training, validation, and test data (features and labels, x and y)\n",
        "split_idx = int(len(features)*0.8)\n",
        "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
        "train_y, remaining_y = y[:split_idx], y[split_idx:]\n",
        "\n",
        "test_idx = int(len(remaining_x)*0.5)\n",
        "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUPLP1FRJiMG"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 10\n",
        "\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size,drop_last = True)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size,drop_last = True)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size,drop_last = True)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv50HxeXkoqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b19de5-55c3-4cf0-cf56-588a73294caa"
      },
      "source": [
        "len(train_loader)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "609"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd5usvv9Jo9P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed360735-f582-41e4-aa4c-5a4d33fbfacc"
      },
      "source": [
        "# First checking if GPU is available\n",
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78qUr4crKBsl"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers,drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super(SentimentRNN, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, batch_first=True)\n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        # linear and sigmoid layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "        \n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        \n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        # dropout and fully connected layer\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        out = self.fc(lstm_out)\n",
        "        \n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        \n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "          hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                   weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "          hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                   weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhjSjnADSMTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d31f586-36ac-4e9d-c945-ca6a2c250c32"
      },
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(vocab_to_int) + 1 # +1 for zero padding + our word tokens\n",
        "output_size = 1\n",
        "embedding_dim = 4000\n",
        "hidden_dim =256\n",
        "n_layers = 1\n",
        "\n",
        "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(15488, 4000)\n",
            "  (lstm): LSTM(4000, 256, batch_first=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB3BsBtTSizj"
      },
      "source": [
        "# loss and optimization functions\n",
        "lr=0.0001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXXI3B06SrA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fc15868-159f-45d3-ff00-3b4b7cb9fbe8"
      },
      "source": [
        "# training params\n",
        "\n",
        "epochs = 10 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "\n",
        "net.train()\n",
        "h2 = []\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "        h2.append(h)\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        \n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if (train_on_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/10... Step: 100... Loss: 0.548883... Val Loss: 0.693454\n",
            "Epoch: 1/10... Step: 200... Loss: 0.674191... Val Loss: 0.700313\n",
            "Epoch: 1/10... Step: 300... Loss: 0.704066... Val Loss: 0.693502\n",
            "Epoch: 1/10... Step: 400... Loss: 0.691175... Val Loss: 0.697022\n",
            "Epoch: 1/10... Step: 500... Loss: 0.759227... Val Loss: 0.683965\n",
            "Epoch: 1/10... Step: 600... Loss: 0.584985... Val Loss: 0.688342\n",
            "Epoch: 2/10... Step: 700... Loss: 0.749580... Val Loss: 0.683742\n",
            "Epoch: 2/10... Step: 800... Loss: 0.654761... Val Loss: 0.681693\n",
            "Epoch: 2/10... Step: 900... Loss: 0.620128... Val Loss: 0.672373\n",
            "Epoch: 2/10... Step: 1000... Loss: 0.682512... Val Loss: 0.675830\n",
            "Epoch: 2/10... Step: 1100... Loss: 0.467894... Val Loss: 0.692829\n",
            "Epoch: 2/10... Step: 1200... Loss: 0.632242... Val Loss: 0.660716\n",
            "Epoch: 3/10... Step: 1300... Loss: 0.583626... Val Loss: 0.654044\n",
            "Epoch: 3/10... Step: 1400... Loss: 0.616806... Val Loss: 0.640647\n",
            "Epoch: 3/10... Step: 1500... Loss: 0.470227... Val Loss: 0.672820\n",
            "Epoch: 3/10... Step: 1600... Loss: 0.536108... Val Loss: 0.612743\n",
            "Epoch: 3/10... Step: 1700... Loss: 0.533266... Val Loss: 0.610085\n",
            "Epoch: 3/10... Step: 1800... Loss: 0.517230... Val Loss: 0.634492\n",
            "Epoch: 4/10... Step: 1900... Loss: 0.425554... Val Loss: 0.589038\n",
            "Epoch: 4/10... Step: 2000... Loss: 0.276925... Val Loss: 0.585471\n",
            "Epoch: 4/10... Step: 2100... Loss: 0.300916... Val Loss: 0.554925\n",
            "Epoch: 4/10... Step: 2200... Loss: 0.383158... Val Loss: 0.566081\n",
            "Epoch: 4/10... Step: 2300... Loss: 0.302417... Val Loss: 0.549794\n",
            "Epoch: 4/10... Step: 2400... Loss: 0.105908... Val Loss: 0.560196\n",
            "Epoch: 5/10... Step: 2500... Loss: 0.179301... Val Loss: 0.561205\n",
            "Epoch: 5/10... Step: 2600... Loss: 0.071657... Val Loss: 0.680291\n",
            "Epoch: 5/10... Step: 2700... Loss: 0.076424... Val Loss: 0.617137\n",
            "Epoch: 5/10... Step: 2800... Loss: 0.212079... Val Loss: 0.640515\n",
            "Epoch: 5/10... Step: 2900... Loss: 0.067502... Val Loss: 0.647667\n",
            "Epoch: 5/10... Step: 3000... Loss: 0.108099... Val Loss: 0.639142\n",
            "Epoch: 6/10... Step: 3100... Loss: 0.154741... Val Loss: 0.712102\n",
            "Epoch: 6/10... Step: 3200... Loss: 0.050570... Val Loss: 0.715027\n",
            "Epoch: 6/10... Step: 3300... Loss: 0.394283... Val Loss: 0.774932\n",
            "Epoch: 6/10... Step: 3400... Loss: 0.038279... Val Loss: 0.747908\n",
            "Epoch: 6/10... Step: 3500... Loss: 0.024010... Val Loss: 0.789179\n",
            "Epoch: 6/10... Step: 3600... Loss: 0.038847... Val Loss: 0.764911\n",
            "Epoch: 7/10... Step: 3700... Loss: 0.056056... Val Loss: 0.768158\n",
            "Epoch: 7/10... Step: 3800... Loss: 0.021146... Val Loss: 0.825439\n",
            "Epoch: 7/10... Step: 3900... Loss: 0.025210... Val Loss: 0.789407\n",
            "Epoch: 7/10... Step: 4000... Loss: 0.019632... Val Loss: 0.809628\n",
            "Epoch: 7/10... Step: 4100... Loss: 0.018247... Val Loss: 0.894499\n",
            "Epoch: 7/10... Step: 4200... Loss: 0.017601... Val Loss: 0.834974\n",
            "Epoch: 8/10... Step: 4300... Loss: 0.024342... Val Loss: 0.842285\n",
            "Epoch: 8/10... Step: 4400... Loss: 0.017168... Val Loss: 0.853936\n",
            "Epoch: 8/10... Step: 4500... Loss: 0.131147... Val Loss: 0.757463\n",
            "Epoch: 8/10... Step: 4600... Loss: 0.017016... Val Loss: 0.941142\n",
            "Epoch: 8/10... Step: 4700... Loss: 0.029264... Val Loss: 0.892358\n",
            "Epoch: 8/10... Step: 4800... Loss: 0.024439... Val Loss: 0.900875\n",
            "Epoch: 9/10... Step: 4900... Loss: 0.024064... Val Loss: 0.996696\n",
            "Epoch: 9/10... Step: 5000... Loss: 0.088550... Val Loss: 0.939003\n",
            "Epoch: 9/10... Step: 5100... Loss: 0.009654... Val Loss: 1.053886\n",
            "Epoch: 9/10... Step: 5200... Loss: 0.066630... Val Loss: 0.995470\n",
            "Epoch: 9/10... Step: 5300... Loss: 0.014503... Val Loss: 0.989830\n",
            "Epoch: 9/10... Step: 5400... Loss: 0.152817... Val Loss: 1.051017\n",
            "Epoch: 10/10... Step: 5500... Loss: 0.011146... Val Loss: 0.929615\n",
            "Epoch: 10/10... Step: 5600... Loss: 0.021665... Val Loss: 0.941495\n",
            "Epoch: 10/10... Step: 5700... Loss: 0.095534... Val Loss: 0.952404\n",
            "Epoch: 10/10... Step: 5800... Loss: 0.014982... Val Loss: 1.056418\n",
            "Epoch: 10/10... Step: 5900... Loss: 0.012384... Val Loss: 1.078308\n",
            "Epoch: 10/10... Step: 6000... Loss: 0.171175... Val Loss: 0.867991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bzs99Na_Vief",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8729c2c7-e763-450f-c1c2-ba8072ee9adc"
      },
      "source": [
        "# Get test data loss and accuracy\n",
        "\n",
        "test_losses = [] # track loss\n",
        "num_correct = 0\n",
        "\n",
        "# init hidden state\n",
        "#h = net.init_hidden(batch_size)\n",
        "\n",
        "net.eval()\n",
        "# iterate over test data\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "    \n",
        "    # get predicted outputs\n",
        "    output, h = net(inputs, h)\n",
        "    \n",
        "    # calculate loss\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    \n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
        "    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "\n",
        "# -- stats! -- ##\n",
        "# avg test loss\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "# accuracy over all test data\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.808\n",
            "Test accuracy: 0.756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmiUOUS1U2Qm",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "6c649e46-d7b6-4775-f86d-a94a9e1d2603"
      },
      "source": [
        "from google.colab import files\n",
        "upload = files.upload()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a91ef177-7670-4aae-a38f-0e8e682b9991\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a91ef177-7670-4aae-a38f-0e8e682b9991\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test.csv to test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtVOHjYjprT1"
      },
      "source": [
        "df_test = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrFiFJlgp5bx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "0e0df72b-e288-4df3-d1a0-0bce9a67573b"
      },
      "source": [
        "df_test"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>10861</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>EARTHQUAKE SAFETY LOS ANGELES Â‰Ã›Ã’ SAFETY FASTE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>10865</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>10868</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>10874</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>10875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id keyword location                                               text\n",
              "0         0     NaN      NaN                 Just happened a terrible car crash\n",
              "1         2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2         3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3         9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4        11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n",
              "...     ...     ...      ...                                                ...\n",
              "3258  10861     NaN      NaN  EARTHQUAKE SAFETY LOS ANGELES Â‰Ã›Ã’ SAFETY FASTE...\n",
              "3259  10865     NaN      NaN  Storm in RI worse than last hurricane. My city...\n",
              "3260  10868     NaN      NaN  Green Line derailment in Chicago http://t.co/U...\n",
              "3261  10874     NaN      NaN  MEG issues Hazardous Weather Outlook (HWO) htt...\n",
              "3262  10875     NaN      NaN  #CityofCalgary has activated its Municipal Eme...\n",
              "\n",
              "[3263 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH5AzkWIp9Wk"
      },
      "source": [
        "X_test = df_test[\"text\"].values"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7daLoUBqLAu"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "target = []\n",
        "context = []\n",
        "BOW1 = []\n",
        "for j in range(3260):\n",
        "  tokenize = tokenize_word(Regularexpreplacer().replace(X_test[j].lower()))\n",
        "  T1 = [lemmatizer.lemmatize(token) for token in tokenize]\n",
        "  BOW1.extend(T1)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9j8UscwqsXx"
      },
      "source": [
        "# feel free to use this import \n",
        "from collections import Counter\n",
        "\n",
        "## Build a dictionary that maps words to integers\n",
        "counts = Counter(BOW1)\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "vocab_to_int = {word: ii for ii, word in enumerate(vocab,1)} \n",
        "\n",
        "## use the dict to tokenize each review in reviews_split\n",
        "## store the tokenized reviews in reviews_ints\n",
        "reviews_ints = []\n",
        "for j in range(3260):\n",
        "  tokenize = tokenize_word(Regularexpreplacer().replace(X_test[j].lower()))\n",
        "  T1 = [lemmatizer.lemmatize(token) for token in tokenize]\n",
        "  reviews_ints.append([vocab_to_int[word] for word in T1])"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXIVMX0urB0c"
      },
      "source": [
        "seq_length = 30\n",
        "\n",
        "features1 = pad_features(reviews_ints, seq_length=seq_length)\n",
        "\n",
        "## test statements - do not change - ##\n",
        "assert len(features1)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
        "assert len(features1[0])==seq_length, \"Each feature row should contain seq_length values.\""
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy-j-7ZRF_0c"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# create Tensor datasets\n",
        "data = TensorDataset(torch.from_numpy(features1))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 10\n",
        "\n",
        "# make sure to SHUFFLE your data\n",
        "data_loader = DataLoader(data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnGIjppZJjFx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b348bcb4-d5f0-4d34-ab58-b634c436dfe4"
      },
      "source": [
        "len(data_loader)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj9UdZrZGb4N"
      },
      "source": [
        "# Get test data loss and accuracy\n",
        "\n",
        "test_losses = [] # track loss\n",
        "num_correct = 0\n",
        "y_pred = []\n",
        "# init hidden state\n",
        "\n",
        "\n",
        "net.eval()\n",
        "# iterate over test data\n",
        "for inputs in data_loader:\n",
        "\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if (train_on_gpu):\n",
        "      inputs = torch.stack(inputs)\n",
        "      inputs = inputs.cuda()\n",
        "      inputs = inputs.squeeze()\n",
        "    # get predicted outputs\n",
        "    output1, h = net(inputs, h)\n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output1.squeeze()) \n",
        "    y_pred.append(pred)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3JxVsx0KX47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ae1f818-ca59-477c-c1f4-a4dcd67093c4"
      },
      "source": [
        "len(y_pred)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqpgp2jEqyB1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1e24bb0-1cf8-435b-89c6-5d600f03e401"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([1., 0., 1., 1., 1., 0., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 0., 0., 1., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 1., 1., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 1., 0., 0., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 1., 1., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 1., 1., 1., 1., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 1., 0., 1., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 1., 1., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 1., 1., 1., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 1., 0., 1., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 1., 0., 1., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 1., 1., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 0., 0., 1., 1., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 0., 0., 1., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 1., 0., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 1., 1., 1., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 1., 0., 0., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 1., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 1., 0., 1., 0., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 1., 0., 0., 1., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 1., 0., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 0., 0., 1., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 1., 1., 1., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 0., 1., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 1., 0., 1., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 0., 0., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 1., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 1., 1., 1., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 1., 0., 0., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 1., 0., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 1., 1., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 1., 0., 1., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 0., 1., 1., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 1., 0., 1., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 1., 0., 1., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 1., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 0., 1., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 1., 1., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 1., 1., 1., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 1., 0., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 0., 1., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 1., 0., 1., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 1., 1., 0., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 1., 0., 1., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 1., 1., 1., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 0., 1., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 1., 0., 0., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 1., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 0., 1., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 1., 0., 1., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 1., 0., 1., 1., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 1., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 0., 0., 0., 0., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 0., 1., 0., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 0., 1., 1., 1., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 1., 0., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 0., 0., 1., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 0., 0., 1., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 1., 0., 1., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 1., 0., 0., 0., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 1., 1., 1., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 0., 1., 1., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 1., 0., 1., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 1., 0., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 1., 0., 1., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 1., 0., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 0., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 0., 1., 0., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 1., 1., 1., 1., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 0., 1., 1., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 0., 0., 1., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 1., 0., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 0., 1., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 0., 1., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 1., 1., 1., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 0., 1., 1., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 0., 0., 0., 1., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 0., 1., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 1., 0., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 1., 1., 0., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 1., 0., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 1., 1., 1., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 1., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 1., 0., 1., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 1., 0., 0., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 1., 1., 0., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 1., 0., 1., 1., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 1., 1., 0., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 0., 0., 1., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 1., 1., 1., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 1., 0., 1., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 0., 0., 0., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 1., 1., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 1., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 1., 1., 0., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 1., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 0., 1., 0., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 0., 0., 0., 1., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 1., 1., 0., 0., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 1., 0., 0., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 1., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 1., 0., 0., 1., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 1., 0., 1., 1., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 1., 1., 0., 1., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 1., 1., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 1., 0., 1., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 1., 0., 1., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 1., 0., 1., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 0., 0., 0., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 0., 1., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 1., 0., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 1., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 1., 1., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 1., 1., 1., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 0., 0., 0., 0., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 1., 0., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 1., 0., 0., 0., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 0., 1., 0., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 1., 0., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 0., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 1., 0., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 1., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 0., 0., 1., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 0., 1., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 0., 1., 1., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 1., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 0., 1., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 1., 0., 1., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 0., 0., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 0., 1., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 1., 1., 0., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 1., 0., 1., 1., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 0., 0., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 0., 1., 1., 1., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 1., 1., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 0., 1., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 0., 1., 0., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 0., 0., 0., 0., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 1., 0., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 1., 0., 1., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 1., 0., 1., 1., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 1., 0., 1., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 0., 0., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 1., 1., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 1., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 0., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 0., 1., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 0., 0., 1., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 1., 0., 1., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 0., 0., 1., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 1., 0., 1., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 1., 0., 1., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 1., 0., 1., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 1., 1., 0., 1., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 0., 1., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 0., 1., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 1., 0., 0., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 1., 0., 0., 1., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 0., 1., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 1., 1., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 0., 0., 1., 1., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 1., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 1., 1., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 0., 0., 0., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 1., 0., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 1., 1., 1., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 0., 1., 1., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 1., 1., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 1., 0., 1., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 1., 0., 0., 1., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 1., 0., 1., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 1., 0., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 1., 1., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 1., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 1., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 1., 1., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 0., 1., 0., 1., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 0., 1., 1., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 1., 0., 1., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 1., 0., 1., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 1., 0., 1., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 1., 0., 1., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 1., 1., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 1., 1., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 0., 0., 1., 1., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 0., 1., 0., 0., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 1., 0., 1., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 0., 0., 0., 1., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 1., 0., 0., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 0., 1., 1., 0., 1., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 1., 0., 1., 0., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 0., 1., 1., 0., 1., 0., 0., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 0., 1., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 0., 0., 0., 1., 0., 0., 0., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 0., 0., 1., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 1., 0., 1., 0., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 1., 1., 0., 1., 0., 1., 1., 0.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>),\n",
              " tensor([1., 1., 1., 0., 1., 0., 1., 1., 1., 1.], device='cuda:0',\n",
              "        grad_fn=<RoundBackward>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEktof3pOdPf"
      },
      "source": [
        "y_pre=[]\n",
        "for i in range(len(y_pred)):\n",
        "  y_pre.append(np.array(y_pred[i].detach().to(torch.device(\"cpu\"))))"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czXj-kqVRsqf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b1b0951-b648-4079-ae20-ea45160edb7a"
      },
      "source": [
        "np.array(y_pre).flatten()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 1., ..., 1., 1., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SsIbpGZnDAr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89bf8d1-9797-41c9-a26c-6f14b13ddb2f"
      },
      "source": [
        "len(np.array(y_pre).flatten())"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3260"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjJVNSoP3tfU",
        "outputId": "9f384488-cca5-413f-dfac-071e4e7e41ff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "# to mounting the drive"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kShKnbt136VT"
      },
      "source": [
        "y_hat = pd.DataFrame(np.array(y_pre).flatten())"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "zGzwDux_4Y5A",
        "outputId": "0ca9408f-4437-47ef-cb31-752d516efd0f"
      },
      "source": [
        "y_hat"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3255</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3256</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3257</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3260 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0\n",
              "0     1.0\n",
              "1     0.0\n",
              "2     1.0\n",
              "3     1.0\n",
              "4     1.0\n",
              "...   ...\n",
              "3255  0.0\n",
              "3256  1.0\n",
              "3257  1.0\n",
              "3258  1.0\n",
              "3259  1.0\n",
              "\n",
              "[3260 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JLZL8DH4e3v"
      },
      "source": [
        "kframe = [df_test[\"text\"],y_hat]"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ6OUlzE43Cf"
      },
      "source": [
        "ki=pd.concat(kframe,axis=1)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehAoxMZs5Ra7"
      },
      "source": [
        "ki=pd.DataFrame(ki)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "5CzCBrgx5dwU",
        "outputId": "e835f197-1510-43b7-b5b2-6076e9179587"
      },
      "source": [
        "ki"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>EARTHQUAKE SAFETY LOS ANGELES Â‰Ã›Ã’ SAFETY FASTE...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text    0\n",
              "0                    Just happened a terrible car crash  1.0\n",
              "1     Heard about #earthquake is different cities, s...  0.0\n",
              "2     there is a forest fire at spot pond, geese are...  1.0\n",
              "3              Apocalypse lighting. #Spokane #wildfires  1.0\n",
              "4         Typhoon Soudelor kills 28 in China and Taiwan  1.0\n",
              "...                                                 ...  ...\n",
              "3258  EARTHQUAKE SAFETY LOS ANGELES Â‰Ã›Ã’ SAFETY FASTE...  1.0\n",
              "3259  Storm in RI worse than last hurricane. My city...  1.0\n",
              "3260  Green Line derailment in Chicago http://t.co/U...  NaN\n",
              "3261  MEG issues Hazardous Weather Outlook (HWO) htt...  NaN\n",
              "3262  #CityofCalgary has activated its Municipal Eme...  NaN\n",
              "\n",
              "[3263 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWGisivg54D1"
      },
      "source": [
        "ki.to_csv('disaster_prediction.csv')\n",
        "# to save the result in my drive of google colab"
      ],
      "execution_count": 107,
      "outputs": []
    }
  ]
}